{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Specifying a model</h2>\n",
    "\n",
    "Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.\n",
    "\n",
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called df. For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. The target, wage_per_hour, is available as a NumPy matrix called target.\n",
    "\n",
    "For all exercises in this chapter, we've imported the Sequential model constructor, the Dense layer constructor, and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/hourly_wages.csv')\n",
    "target = np.array(df['wage_per_hour'])\n",
    "#predictors = np.array(df.iloc[:, 1:]).as_matrix()\n",
    "predictors = df.drop(['wage_per_hour'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compiling the model</h2>\n",
    "\n",
    "You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. In the video, Dan mentioned that the Adam optimizer is an excellent choice. You can read more about it as well as other keras optimizers here, and if you are really curious to learn more, you can read the original paper that introduced the Adam optimizer.\n",
    "\n",
    "In this exercise, you'll use the Adam optimizer and the mean squared error loss function. Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fitting the model</h2>\n",
    "\n",
    "You're at the most fun part. You'll now fit the model. Recall that the data to be used as predictive features is loaded in a NumPy matrix called predictors and the data to be predicted is stored in a NumPy matrix called target. Your model is pre-written and it has been compiled with the code from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "534/534 [==============================] - 0s 661us/step - loss: 151.2172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22379baaa58>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superb! You now know how to specify, compile, and fit a deep learning model using keras!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Understanding your classification data</h2>\n",
    "\n",
    "Now you will start modeling with a new dataset for a classification problem. This data includes information about passengers on the Titanic. You will use predictors such as age, fare and where each passenger embarked from to predict who will survive. This data is from a tutorial on data science competitions. Look here for descriptions of the features.\n",
    "\n",
    "The data is pre-loaded in a pandas DataFrame called df.\n",
    "\n",
    "It's smart to review the maximum and minimum values of each variable to ensure the data isn't misformatted or corrupted. What was the maximum age of passengers on the Titanic? Use the .describe() method in the IPython Shell to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
      "0         0       3  22.0      1      0   7.2500     1            False   \n",
      "1         1       1  38.0      1      0  71.2833     0            False   \n",
      "2         1       3  26.0      0      0   7.9250     0            False   \n",
      "3         1       1  35.0      1      0  53.1000     0            False   \n",
      "4         0       3  35.0      0      0   8.0500     1            False   \n",
      "\n",
      "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
      "0                        0                         0   \n",
      "1                        1                         0   \n",
      "2                        0                         0   \n",
      "3                        0                         0   \n",
      "4                        0                         0   \n",
      "\n",
      "   embarked_from_southampton  \n",
      "0                          1  \n",
      "1                          0  \n",
      "2                          1  \n",
      "3                          1  \n",
      "4                          1  \n",
      "         survived      pclass         age       sibsp       parch        fare  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208   \n",
      "std      0.486592    0.836071   13.002015    1.102743    0.806057   49.693429   \n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400   \n",
      "50%      0.000000    3.000000   29.699118    0.000000    0.000000   14.454200   \n",
      "75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000   \n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200   \n",
      "\n",
      "             male  embarked_from_cherbourg  embarked_from_queenstown  \\\n",
      "count  891.000000               891.000000                891.000000   \n",
      "mean     0.647587                 0.188552                  0.086420   \n",
      "std      0.477990                 0.391372                  0.281141   \n",
      "min      0.000000                 0.000000                  0.000000   \n",
      "25%      0.000000                 0.000000                  0.000000   \n",
      "50%      1.000000                 0.000000                  0.000000   \n",
      "75%      1.000000                 0.000000                  0.000000   \n",
      "max      1.000000                 1.000000                  1.000000   \n",
      "\n",
      "       embarked_from_southampton  \n",
      "count                 891.000000  \n",
      "mean                    0.722783  \n",
      "std                     0.447876  \n",
      "min                     0.000000  \n",
      "25%                     0.000000  \n",
      "50%                     1.000000  \n",
      "75%                     1.000000  \n",
      "max                     1.000000  \n"
     ]
    }
   ],
   "source": [
    "df =pd.read_csv('data/titanic_all_numeric.csv')\n",
    "print(df.head())\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "target = np.array(df['survived'])\n",
    "predictors = df.drop(['survived'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Last steps in classification models</h2>\n",
    "\n",
    "You'll now create a classification model using the titanic dataset, which has been pre-loaded into a DataFrame called df. You'll take information about the passengers and predict which ones survived.\n",
    "\n",
    "The predictive variables are stored in a NumPy array predictors. The target to predict is in df.survived, though you'll have to manipulate it for keras. The number of predictive features is stored in n_cols.\n",
    "\n",
    "Here, you'll use the 'sgd' optimizer, which stands for Stochastic Gradient Descent. You'll learn more about this in the next chapter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 364us/step - loss: 1.7898 - acc: 0.6128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2237dc873c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! This simple model is generating an accuracy of 60!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Making predictions</h2>\n",
    "\n",
    "The trained network from your previous coding exercise is now stored as model. New data to make predictions is stored in a NumPy array as pred_data. Use model to make predictions on your new data.\n",
    "\n",
    "In this exercise, your predictions will be probabilities, which is the most common way for data scientists to communicate their predictions to colleagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.array([[2, 34.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 26.25, 0, False, 0, 0, 1],\n",
    "       [1, 11.0, 1, 2, 120.0, 1, False, 0, 0, 1],\n",
    "       [3, 0.42, 0, 1, 8.5167, 1, False, 1, 0, 0],\n",
    "       [3, 27.0, 0, 0, 6.975, 1, False, 0, 0, 1],\n",
    "       [3, 31.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 7.775, 0, False, 0, 0, 1],\n",
    "       [2, 39.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 33.0, 1, 0, 53.1, 0, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8875, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 0, 24.15, 1, False, 0, 0, 1],\n",
    "       [2, 35.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 6.0, 4, 2, 31.275, 0, False, 0, 0, 1],\n",
    "       [3, 30.5, 0, 0, 8.05, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 0.0, 1, True, 0, 0, 1],\n",
    "       [3, 23.0, 0, 0, 7.925, 0, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 43.0, 0, 0, 6.45, 1, False, 0, 0, 1],\n",
    "       [3, 10.0, 3, 2, 27.9, 1, False, 0, 0, 1],\n",
    "       [1, 52.0, 1, 1, 93.5, 0, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [1, 38.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 1, 12.475, 0, False, 0, 0, 1],\n",
    "       [3, 2.0, 4, 1, 39.6875, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 6.95, 1, True, 0, 1, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 56.4958, 1, True, 0, 0, 1],\n",
    "       [2, 1.0, 0, 2, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.75, 1, True, 0, 1, 0],\n",
    "       [1, 62.0, 0, 0, 80.0, 0, False, 0, 0, 0],\n",
    "       [3, 15.0, 1, 0, 14.4542, 0, False, 1, 0, 0],\n",
    "       [2, 0.83, 1, 1, 18.75, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 23.0, 0, 0, 7.8542, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 8.3, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 1, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [3, 21.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 8.05, 1, True, 0, 0, 1],\n",
    "       [3, 32.0, 0, 0, 56.4958, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 29.7, 1, True, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 7.925, 1, False, 0, 0, 1],\n",
    "       [2, 16.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [1, 30.0, 0, 0, 31.0, 0, False, 1, 0, 0],\n",
    "       [3, 34.5, 0, 0, 6.4375, 1, False, 1, 0, 0],\n",
    "       [3, 17.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 42.0, 0, 0, 7.55, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 1, True, 0, 0, 1],\n",
    "       [3, 35.0, 0, 0, 7.8958, 1, False, 1, 0, 0],\n",
    "       [2, 28.0, 0, 1, 33.0, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 1, 0, 89.1042, 0, True, 1, 0, 0],\n",
    "       [3, 4.0, 4, 2, 31.275, 1, False, 0, 0, 1],\n",
    "       [3, 74.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [3, 9.0, 1, 1, 15.2458, 0, False, 1, 0, 0],\n",
    "       [1, 16.0, 0, 1, 39.4, 0, False, 0, 0, 1],\n",
    "       [2, 44.0, 1, 0, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 1, 9.35, 0, False, 0, 0, 1],\n",
    "       [1, 45.0, 1, 1, 164.8667, 0, False, 0, 0, 1],\n",
    "       [1, 51.0, 0, 0, 26.55, 1, False, 0, 0, 1],\n",
    "       [3, 24.0, 0, 3, 19.2583, 0, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 41.0, 2, 0, 14.1083, 1, False, 0, 0, 1],\n",
    "       [2, 21.0, 1, 0, 11.5, 1, False, 0, 0, 1],\n",
    "       [1, 48.0, 0, 0, 25.9292, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 0, True, 0, 0, 1],\n",
    "       [2, 24.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 42.0, 0, 0, 13.0, 0, False, 0, 0, 1],\n",
    "       [2, 27.0, 1, 0, 13.8583, 0, False, 1, 0, 0],\n",
    "       [1, 31.0, 0, 0, 50.4958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 9.5, 1, True, 0, 0, 1],\n",
    "       [3, 4.0, 1, 1, 11.1333, 1, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [1, 47.0, 1, 1, 52.5542, 0, False, 0, 0, 1],\n",
    "       [1, 33.0, 0, 0, 5.0, 1, False, 0, 0, 1],\n",
    "       [3, 47.0, 0, 0, 9.0, 1, False, 0, 0, 1],\n",
    "       [2, 28.0, 1, 0, 24.0, 0, False, 1, 0, 0],\n",
    "       [3, 15.0, 0, 0, 7.225, 0, False, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 9.8458, 1, False, 0, 0, 1],\n",
    "       [3, 19.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.8958, 1, True, 0, 0, 1],\n",
    "       [1, 56.0, 0, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [2, 25.0, 0, 1, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 33.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 22.0, 0, 0, 10.5167, 0, False, 0, 0, 1],\n",
    "       [2, 28.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 25.0, 0, 0, 7.05, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 5, 29.125, 0, False, 0, 1, 0],\n",
    "       [2, 27.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 19.0, 0, 0, 30.0, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 1, 2, 23.45, 0, True, 0, 0, 1],\n",
    "       [1, 26.0, 0, 0, 30.0, 1, False, 1, 0, 0],\n",
    "       [3, 32.0, 0, 0, 7.75, 1, False, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 460us/step - loss: 2.1109 - acc: 0.6094\n",
      "[0.66209066 0.91098976 1.         0.7070526  0.590956   0.59338516\n",
      " 0.43708327 0.560862   0.64933497 0.99986446 0.6027206  0.78643453\n",
      " 0.61978126 0.99532205 0.59931844 0.48577434 0.5605551  0.9966968\n",
      " 0.5376353  0.99411917 1.         0.6115672  0.43863562 0.6637424\n",
      " 0.99756527 0.6313019  0.99995923 0.99760985 0.64406943 0.99999523\n",
      " 0.79569    0.95444363 0.6667447  0.60357976 0.6109985  0.9999999\n",
      " 0.6140625  0.63445497 0.9999347  0.98267823 0.6056851  0.64920866\n",
      " 0.9836993  0.6216441  0.61572284 0.5592499  0.99999726 0.6421515\n",
      " 0.9930328  1.         0.99428916 0.47302955 0.91148055 0.9997002\n",
      " 0.7480699  0.63161856 1.         0.80163234 0.8957321  0.6667447\n",
      " 0.5121428  0.58177257 0.7977826  0.9999969  0.67411155 0.61826795\n",
      " 0.61913383 0.99983406 0.65113944 0.8444316  0.6028203  0.99946874\n",
      " 0.5246981  0.5699823  0.8863326  0.60003585 0.6284287  0.6057542\n",
      " 0.6326608  0.99999917 0.9694421  0.5899407  0.5926822  0.6382393\n",
      " 0.5930506  0.9436727  0.6729553  0.993145   0.8790683  0.98987645\n",
      " 0.6022272 ]\n"
     ]
    }
   ],
   "source": [
    "# Specify, compile, and fit the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Changing optimization parameters</h2>\n",
    "\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
    "\n",
    "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (predictors.shape[1],)\n",
    "def get_new_model(input_shape = input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 570us/step - loss: 1.5555 - acc: 0.3558\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 614us/step - loss: 1.3841 - acc: 0.6251\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 642us/step - loss: 5.9612 - acc: 0.6105\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr = lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer = my_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluating model accuracy on validation dataset</h2>\n",
    "\n",
    "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as model. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/1\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 2.7874 - acc: 0.5618 - val_loss: 0.9271 - val_acc: 0.7201\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Early stopping: Optimizing the optimization</h2>\n",
    "\n",
    "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for epochs in your call to .fit(), as Dan showed in the video.\n",
    "\n",
    "The model you'll optimize has been specified as model. As before, the data is pre-loaded as predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 1.1530 - acc: 0.6196 - val_loss: 0.6799 - val_acc: 0.6604\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.6490 - acc: 0.6565 - val_loss: 0.5304 - val_acc: 0.7463\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.6475 - acc: 0.6854 - val_loss: 0.5247 - val_acc: 0.7201\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.6294 - acc: 0.6886 - val_loss: 0.5294 - val_acc: 0.7313\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.5802 - acc: 0.7079 - val_loss: 0.6976 - val_acc: 0.6679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22303b5d160>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, epochs=30, validation_split=0.3, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful work! Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that you've used so far. Here, it seems like the optimization stopped after 5 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Experimenting with wider networks</h2>\n",
    "\n",
    "Now you know everything you need to begin experimenting with different models!\n",
    "\n",
    "A model called model_1 has been pre-loaded. You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called model_2 which is similar to model_1, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument verbose=False in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\n",
    "\n",
    "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_1\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_1.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam',  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam',  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue model is the one you made, the red is the original model. Your model had a lower loss value, so it is the better model. Nice job!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adding layers to a network</h2>\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called model_1 as a starting point. It has 1 hidden layer, with 50 units. You can see a summary of that model's structure printed out. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_1\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! The blue model is the one you made and the red is the original model. The model with the lower loss value is the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building your own digit recognition model</h2>\n",
    "\n",
    "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!\n",
    "\n",
    "We've already done the basic manipulation of the MNIST dataset shown in the video, so you have X and y loaded and ready to model with. Sequential and Dense from keras are also pre-imported.\n",
    "\n",
    "To add an extra challenge, we've loaded only 2500 images, rather than 60000 which you will see in some published results. Deep learning models perform better with more data, however, they also take longer to train, especially when they start becoming more complex.\n",
    "\n",
    "If you have a computer with a CUDA compatible GPU, you can take advantage of it to improve computation time. If you don't have a GPU, no problem! You can set up a deep learning environment in the cloud that can run your models on a GPU. Here is a <a href='https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws'>blog post</a> by Dan that explains how to do this - check it out after completing this exercise! It is a great next step as you continue your deep learning journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/mnist (1).csv')\n",
    "y = to_categorical(df['5'])\n",
    "X = df.drop('5', axis=1).values\n",
    "#print(X)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "1400/1400 [==============================] - 2s 1ms/step - loss: 12.4480 - acc: 0.2171 - val_loss: 12.0926 - val_acc: 0.2467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2230ee9fb00>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
